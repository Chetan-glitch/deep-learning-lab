import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_circles

# -----------------------------
# Part 1: Linearly Separable Data
# -----------------------------

np.random.seed(42)

# Generate 2D input data
X = np.random.normal(0, 1, (200, 2))

# Define labels using a simple linear rule
y = (X[:, 0] - X[:, 1] > 0).astype(int).reshape(-1, 1)

# Hyperparameters
lr = 0.1
epochs = 1000

# Initialize parameters
W = np.random.uniform(-1, 1, (2, 1))
b = 0.0

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Training loop
for epoch in range(epochs):
    z = np.matmul(X, W) + b
    y_hat = sigmoid(z)

    # Gradients
    dW = np.matmul(X.T, (y_hat - y)) / X.shape[0]
    db = np.sum(y_hat - y) / X.shape[0]

    # Parameter update
    W -= lr * dW
    b -= lr * db

# Plot decision boundary
plt.figure(figsize=(6, 5))
plt.scatter(X[:, 0], X[:, 1], c=y.flatten(), cmap="coolwarm", alpha=0.6)

x_vals = np.linspace(-3, 3, 100)
y_vals = -(W[0] * x_vals + b) / W[1]

plt.plot(x_vals, y_vals, color="black")
plt.title("Perceptron on Linearly Separable Data")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()


# --------------------------------
# Part 2: Non-Linearly Separable Data
# --------------------------------

X_circle, y_circle = make_circles(n_samples=300, noise=0.1, factor=0.5)
y_circle = y_circle.reshape(-1, 1)

plt.figure(figsize=(6, 5))
plt.scatter(X_circle[:, 0], X_circle[:, 1],
            c=y_circle.flatten(), cmap="coolwarm")
plt.title("Non-Linearly Separable Dataset (Circles)")
plt.xlabel("X1")
plt.ylabel("X2")
plt.show()
